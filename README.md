# ðŸš€ Curso de introducciÃ³n a microservicios

## ðŸ“‹ DescripciÃ³n

Este proyecto es una arquitectura de **microservicios** construida con Go, Gin Framework y GORM. Cada endpoint ha sido desacoplado en su propio servicio independiente y "containerizado" con Docker.

## ðŸ“‚ Estructura del Proyecto

- ðŸ“¦ `pkg/`: Paquetes compartidos (conexiÃ³n DB, modelos).
- ðŸ”§ `services/`: CÃ³digo fuente de cada microservicio.
- ðŸ³ `docker-compose.yml`: OrquestaciÃ³n de contenedores.
- ðŸ“® `intro_microservicios_collection.json`: ColecciÃ³n de Postman para probar la API.

## ðŸ—„ï¸ ConfiguraciÃ³n de Base de Datos

El proyecto incluye un contenedor de PostgreSQL configurado automÃ¡ticamente en el `docker-compose.yml`.

- ðŸ‘¤ **Credenciales**: Usuario `devuser`, ContraseÃ±a `devpassword123`.
- ðŸ“Š **Database**: `intro_microservicios`.

## ðŸ³ EjecuciÃ³n con Docker Compose

La forma recomendada de levantar todo el entorno es usando Docker Compose. Esto iniciarÃ¡ la base de datos y todos los microservicios, mapeando sus puertos para acceso local.

```bash
docker-compose up --build
```

Una vez desplegado, los servicios estarÃ¡n disponibles a travÃ©s del **API Gateway (Nginx)** en el puerto **8000**. Ya no es necesario acceder a puertos individuales.

| Servicio | Ruta (Gateway) | MÃ©todo | URL Local |
|----------|----------------|--------|-----------|
| GetAdults | `/Adults` | GET | `http://localhost:8000/Adults` |
| GetChildren | `/Children` | GET | `http://localhost:8000/Children` |
| GetAdultById | `/Adults/:id` | GET | `http://localhost:8000/Adults/{id}` |
| GetChildById | `/Children/:id` | GET | `http://localhost:8000/Children/{id}` |
| AddMember | `/Add/Member` | POST | `http://localhost:8000/Add/Member` |
| AddAdult | N/A (Kafka Consumer) | - | Event-driven desde PickAge |
| AddChild | N/A (Kafka Consumer) | - | Event-driven desde PickAge |
| PickAge | N/A (Kafka Consumer/Producer) | - | Event-driven desde AddMember |

> **Nota**: Los servicios `AddAdult`, `AddChild` y `PickAge` son **Kafka Consumers** sin endpoint HTTP. Funcionan de forma event-driven en el flujo de mensajerÃ­a.

## ðŸ“¨ Servicio AddMember (Kafka)

El servicio `add-member` implementa integraciÃ³n con **Apache Kafka** para publicar eventos de miembros agregados.

### âœ¨ CaracterÃ­sticas

- ðŸ“¤ **Productor de Kafka**: EnvÃ­a mensajes del nuevo miembro al topic `pickage`.
- ðŸ’‰ **InyecciÃ³n de Dependencias**: El broker de Kafka se inyecta desde la configuraciÃ³n.
- âš™ï¸ **GestiÃ³n de ConfiguraciÃ³n**: Carga variables desde `.env` usando `godotenv`.
- ðŸŽ¯ **Manejo de TÃ³pics**: Crea automÃ¡ticamente el topic si no existe.

### âš™ï¸ ConfiguraciÃ³n

El servicio requiere la variable de entorno `KAFKA_BROKER`:

```bash
KAFKA_BROKER=kafka:9092  # Para desarrollo con Docker
KAFKA_BROKER=localhost:9093  # Para cliente externo
```

En Docker Compose, esta variable se define automÃ¡ticamente a travÃ©s de `KAFKA_BROKER: kafka:9092`.

### ðŸ“ Estructura del Servicio

```
services/add-member/
â”œâ”€â”€ cmd/main.go                  # Punto de entrada principal
â”œâ”€â”€ config/config.go             # GestiÃ³n de configuraciÃ³n
â”œâ”€â”€ handlers/add_member_handler.go # LÃ³gica de negocio
â”œâ”€â”€ kafka/producer.go            # Productor de Kafka
â”œâ”€â”€ models/member.go             # Modelo de datos
â”œâ”€â”€ .env.example                 # Plantilla de variables
â””â”€â”€ Dockerfile                   # ConfiguraciÃ³n de contenedor
```

### ðŸ”§ Optimizaciones de Kafka

**ðŸ§ª Para Pruebas**:

- â±ï¸ RetenciÃ³n: 24 horas
- ðŸ”„ Auto-creaciÃ³n de topics: Habilitada
- ðŸ”— SincronizaciÃ³n: RequireOne (solo el lÃ­der confirma)

**ðŸ¢ Para ProducciÃ³n** (8GB RAM, 15GB storage):

- â±ï¸ RetenciÃ³n: 72 horas (3 dÃ­as)
- ðŸ’¾ Almacenamiento: MÃ¡ximo 10GB
- ðŸ”— SincronizaciÃ³n: RequireAll (todas las replicas confirman)

Ver configuraciÃ³n en `docker-compose.yml` secciÃ³n Kafka.

## ðŸ“Š Servicio PickAge (Kafka Consumer Simple)

El servicio `pick-age` es un **consumidor de Kafka** que escucha el topic `pickage` y loguea si los miembros son adultos (18+) o menores de edad.

### ðŸ”„ Flujo de Proceso

1. **Recibe**: Escucha mensajes del topic `pickage` (publicados por `add-member`)
2. **Procesa**: Calcula edad basÃ¡ndose en el aÃ±o de nacimiento actual
3. **Loguea**: 
   - `ðŸ‘¤ ADULTO: [Nombre] [Apellido] - Nacido en [AÃ±o] (edad: [AÃ±os] aÃ±os)` si tiene 18+
   - `ðŸ‘¶ MENOR: [Nombre] [Apellido] - Nacido en [AÃ±o] (edad: [AÃ±os] aÃ±os)` si es menor

### ðŸ“ Estructura del Servicio

```
services/pick-age/
â”œâ”€â”€ cmd/main.go              # Punto de entrada
â”œâ”€â”€ config/config.go         # GestiÃ³n de configuraciÃ³n
â”œâ”€â”€ kafka/consumer.go        # Consumer que procesa directamente
â”œâ”€â”€ models/member.go         # Modelo de datos
â”œâ”€â”€ .env.example             # Plantilla de variables
â””â”€â”€ Dockerfile               # ConfiguraciÃ³n de contenedor
```

### âœ¨ CaracterÃ­sticas

- ðŸ‘‚ **Consumer de Kafka**: Escucha el topic `pickage` continuamente
- ðŸ” **AnÃ¡lisis de Edad**: Calcula edad en tiempo real
- ðŸ“ **Logging Simple**: Loguea adultos vs menores
- ðŸŽ¯ **Sin Complejidades**: No usa producers, handlers, ni base de datos
- ðŸš« **Sin HTTP**: Puramente event-driven

Ver configuraciÃ³n en `docker-compose.yml` secciÃ³n Kafka.

## ðŸ§ª Pruebas

### ðŸ“® OpciÃ³n 1: Postman

1. Abre Postman.
2. Importa el archivo `intro_microservicios_collection.json` ubicado en la raÃ­z del proyecto.
3. Ejecuta las peticiones directamente contra el entorno local desplegado con Docker.

### ðŸ’» OpciÃ³n 2: VS Code REST Client

Si utilizas la extensiÃ³n **REST Client** en VS Code, puedes ejecutar las peticiones directamente desde el editor:

1. Abre el archivo `requests.http`.
2. Haz clic en "Send Request" sobre cada definiciÃ³n de endpoint.

---

## ðŸ—ï¸ Flujo de Microservicios con Kafka

El sistema implementa un flujo event-driven utilizando Apache Kafka como bus de mensajerÃ­a:

### ðŸ“Š Diagrama de Flujo

```
[Cliente HTTP]
      â†“
[POST /Add/Member] â†’ add-member service
      â†“
  [Produce] â†’ Topic: "members.registration.fct.member.received"
      â†“
[pick-age service]
      â”œâ”€â†’ Classifica por edad
      â”œâ”€â†’ Si edad >= 18: [Produce] â†’ "members.classification.fct.adult.validated"
      â””â”€â†’ Si edad < 18: [Produce] â†’ "members.classification.fct.child.validated"
      â†“
[Consumers]
â”œâ”€â†’ add-adult service (consume "members.classification.fct.adult.validated")
â”‚   â””â”€â†’ Guarda en tabla "adults"
â”‚
â””â”€â†’ add-child service (consume "members.classification.fct.child.validated")
    â””â”€â†’ Guarda en tabla "children"
```

### ðŸ“¨ Servicio AddMember (Kafka Producer)

El servicio `add-member` sigue siendo el punto de entrada HTTP. Recibe un miembro y lo publica al topic `members.registration.fct.member.received`.

**Endpoints:**
- `POST /Add/Member` â†’ Publica evento de miembro registrado

**Topics producidos:**
- `members.registration.fct.member.received`

---

### ðŸ”„ Servicio PickAge (Kafka Consumer â†’ Producer)

El servicio `pick-age` consume miembros registrados, calcula su edad y los clasifica.

**Arquitectura SOLID:**
- `classifier/classifier.go`: LÃ³gica de clasificaciÃ³n (SRP)
- `kafka/consumer.go`: Lectura de eventos (SRP)
- `kafka/producer.go`: PublicaciÃ³n de eventos clasificados (SRP)

**Topics consumidos:**
- `members.registration.fct.member.received`

**Topics producidos:**
- `members.classification.fct.adult.validated` (edad >= 18)
- `members.classification.fct.child.validated` (edad < 18)

**GroupID:** `pick-age-service`

---

### ðŸ‘¤ Servicio AddAdult (Kafka Consumer)

El servicio `add-adult` consume adultos clasificados y los guarda en la base de datos.

**Ya NO tiene endpoint HTTP** - Es puramente event-driven.

**Arquitectura SOLID:**
- `repository/adult_repository.go`: Acceso a datos (SRP)
- `kafka/consumer.go`: Lectura de eventos (SRP)
- `config/config.go`: GestiÃ³n de configuraciÃ³n (SRP)

**Topics consumidos:**
- `members.classification.fct.adult.validated`

**Base de datos:**
- Tabla: `adults` (crea automÃ¡ticamente adultos)

**GroupID:** `add-adult-service`

---

### ðŸ‘¶ Servicio AddChild (Kafka Consumer)

Similar a `add-adult`, este servicio consume menores clasificados y los guarda en la base de datos.

**Ya NO tiene endpoint HTTP** - Es puramente event-driven.

**Arquitectura SOLID:**
- `repository/child_repository.go`: Acceso a datos (SRP)
- `kafka/consumer.go`: Lectura de eventos (SRP)
- `config/config.go`: GestiÃ³n de configuraciÃ³n (SRP)

**Topics consumidos:**
- `members.classification.fct.child.validated`

**Base de datos:**
- Tabla: `children` (crea automÃ¡ticamente menores)

**GroupID:** `add-child-service`
